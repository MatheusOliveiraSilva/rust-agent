# Roadmap â€” â€œAgentrixâ€ (Rust ReAct Agent + MCP + CLI)

> Objetivo: construir um agente estilo LangGraph (ReAct) com streaming, LLM factory, MCP tools (server+client) e uma CLI simples. Vamos progredir em *blocos semÃ¢nticos*, cada um com **entregÃ¡veis**, **testes manuais** e **commits** sugeridos. **Sem cÃ³digo agora** â€” sÃ³ o trilho de execuÃ§Ã£o.

---

## Fase 0 â€” Boot do workspace

* [ ] **Criar workspace Cargo** (`agentrix/`) com crates: `core`, `llm`, `mcp-server`, `cli`.
* [ ] **ConfiguraÃ§Ã£o base**: `tokio`, `reqwest` (com `json` + `rustls-tls`), `serde`, `serde_json`, `anyhow`, `thiserror`, `tracing`, `tracing-subscriber`.
* [ ] **Lint/format**: `rustfmt`, `clippy`.
* [ ] **README** com visÃ£o geral + como rodar.
* ğŸ§ª **Teste manual**: `cargo build -p cli` compila; `cargo test` vazio passando.
* ğŸ’¾ **Commit**: `chore: init cargo workspace and deps`

---

## Fase 1 â€” NÃºcleo de tipos e eventos (core)

* [ ] **Tipos base**: `Message { role, content }`, `Role`, `LlmConfig`.
* [ ] **Eventos de streaming**: `Event::{StateEnter, StateExit, ModelDelta, ToolCall, ToolResult, FinalText, Error}`.
* [ ] **Contexto do grafo**: `GraphContext { llm, history, event_tx }`.
* [ ] **Interface de nÃ³**: `AgentNode` (trait `async`).
* [ ] **Executor linear**: `Graph::new(...).run(ctx)`.
* ğŸ§ª **Teste manual**: criar `Graph` com nÃ³ â€œfakeâ€ que emite `StateEnter/Exit`; ver eventos num `mpsc` local.
* ğŸ’¾ **Commit**: `feat(core): base types and event bus`

---

## Fase 2 â€” CLI esqueleto (sem LLM)

* [ ] **CLI REPL**: ler linhas do `stdin`, manter `history` em memÃ³ria.
* [ ] **Impressor de eventos**: task separada consumindo `mpsc::UnboundedReceiver<Event>`, imprimindo estado/erros.
* [ ] **Rodada vazia**: ao digitar algo, cria `Graph` com 1 nÃ³ â€œechoâ€ que gera um `FinalText` com o input.
* ğŸ§ª **Teste manual**: `cargo run -p cli`, digitar â€œolÃ¡â€ e ver `FinalText: olÃ¡`.
* ğŸ’¾ **Commit**: `feat(cli): repl + event printer`

---

## Fase 3 â€” LLM trait + Factory (sem provider ainda)

* [ ] **Trait `Llm`**: mÃ©todo `stream_chat(system, messages, tools) -> Stream<Event>`.
* [ ] **`ToolSpec`**: descriÃ§Ã£o opcional para function-calling futuro.
* [ ] **Factory `LlmFactory::make(LlmConfig)`**: valida provider/modelo.
* [ ] **Helper** pra clonar como `Box<dyn Llm>` (ex.: `to_owned_box()`).
* ğŸ§ª **Teste manual**: mock de LLM que streama â€œhello â€, â€œworldâ€ em `ModelDelta`.
* ğŸ’¾ **Commit**: `feat(llm): trait and factory with mock`

---

## Fase 4 â€” Provider OpenAI (streaming)

* [ ] **OpenAI impl**: chamada `chat.completions` com `stream=true`, parsing SSE â†’ `Event::ModelDelta` e `Event::ToolCall` (se houver).
* [ ] **Config** por env: `OPENAI_API_KEY`; `LlmConfig.model/provider`.
* [ ] **Erros**: mapear 4xx/5xx e rede (propagar em `Event::Error` ao stream).
* ğŸ§ª **Teste manual**: CLI â†’ pergunta simples; ver texto chegando em *chunks* (`ModelDelta`) e um `FinalText`.
* ğŸ’¾ **Commit**: `feat(llm-openai): streaming SSE + error mapping`

---

## Fase 5 â€” ReAct mÃ­nimo (Plan â†’ Decide)

* [ ] **`PlanNode`**: injeta instruÃ§Ã£o `system` bÃ¡sica no `history`.
* [ ] **`DecideNode`**: chama `llm.stream_chat(...)`, reenviando `ModelDelta` e consolidando `FinalText`.
* [ ] **IntegraÃ§Ã£o CLI**: rodar grafo `Plan -> Decide` a cada input do usuÃ¡rio.
* ğŸ§ª **Teste manual**: perguntar â€œo que Ã© Rust?â€; ver stream e resposta final; `history` crescendo.
* ğŸ’¾ **Commit**: `feat(core): minimal ReAct plan/decide flow`

---

## Fase 6 â€” MCP Server (tools de exemplo)

* [ ] **Crate `mcp-server`** com transporte `stdio`.
* [ ] **Tools**: `get_time()`, `echo(text)`. (Simples, sÃ³ para provar integraÃ§Ã£o).
* [ ] **Lifecycle**: sobe, serve e encerra limpeza.
* ğŸ§ª **Teste manual**: rodar `mcp-server` sozinho; verificar que inicia sem erro.
* ğŸ’¾ **Commit**: `feat(mcp-server): stdio server with basic tools`

---

## Fase 7 â€” MCP Client (invocaÃ§Ã£o de tools)

* [ ] **Wrapper `McpClient`**: conectar via `spawn` do processo `mcp-server` (stdio).
* [ ] **API**: `call(name, args) -> serde_json::Value`.
* [ ] **ResiliÃªncia**: restart opcional se o child cair (deixar anotado para fase posterior).
* ğŸ§ª **Teste manual**: binÃ¡rio temporÃ¡rio que chama `McpClient::call("get_time")` e imprime JSON.
* ğŸ’¾ **Commit**: `feat(core): mcp client wrapper (spawn stdio child)`

---

## Fase 8 â€” Act/Observe Nodes + Tool streaming

* [ ] **`DecideNode`** detecta `Event::ToolCall` â†’ encaminha para **`ActNode`**.
* [ ] **`ActNode`**: usa `McpClient` para executar; emite `Event::ToolResult`.
* [ ] **`ObserveNode`**: adiciona `tool_result` ao `history` e retorna para decisÃ£o (loop 1 passo).
* [ ] **Ciclo**: Plan â†’ Decide (toolcall?) â†’ Act â†’ Observe â†’ Decide (resposta final).
* ğŸ§ª **Teste manual**: prompt que induza ferramenta (`get_time`); ver `toolcall` â†’ `tool_result` â†’ resposta incorporando o resultado.
* ğŸ’¾ **Commit**: `feat(core): act/observe nodes with MCP tool execution`

---

## Fase 9 â€” UX de CLI (feedback visual simples)

* [ ] **Status**: `[state]` com `StateEnter/Exit`.
* [ ] **Tool feedback**: `[toolcall] name args` e `[tool_result] ok=â€¦`.
* [ ] **Append de texto**: imprimir deltas sem quebrar linha; consolidar ao final.
* [ ] **Ctrl+C**: encerramento limpo; dreno de eventos.
* ğŸ§ª **Teste manual**: conversar, ver fluxo limpo, sem â€œpularâ€ cursor.
* ğŸ’¾ **Commit**: `feat(cli): polished event printing and graceful shutdown`

---

## Fase 10 â€” ConfiguraÃ§Ã£o e DX

* [ ] **Flags/ENV**: `--provider`, `--model`, `--reasoning`, `--mcp-bin` (caminho do server), `--verbose`.
* [ ] **`tracing`**: `RUST_LOG` controlando logs (debug para rede/MCP).
* [ ] **Mensagens de erro amigÃ¡veis** (sem vazar stack crua no modo padrÃ£o).
* ğŸ§ª **Teste manual**: trocar modelos e nÃ­vel de log via flags/env.
* ğŸ’¾ **Commit**: `feat(cli): flags for provider/model and logging`

---

## Fase 11 â€” PersistÃªncia de sessÃ£o

* [ ] **Salvar/Carregar**: `--session file.json` (history + config).
* [ ] **Append**: ao enviar nova mensagem, atualiza arquivo.
* [ ] **Compatibilidade**: versÃ£o do schema no JSON.
* ğŸ§ª **Teste manual**: iniciar conversa, sair, retornar com o mesmo `--session`.
* ğŸ’¾ **Commit**: `feat(core/cli): session persistence (save/load)`

---

## Fase 12 â€” Testes automatizados

* [ ] **Tests unit**: serializaÃ§Ã£o de `Event`, `Message`, `LlmConfig`.
* [ ] **Test double** de LLM (mock stream) para testar ReAct sem rede.
* [ ] **Test e2e** (feature flag `offline`): grafo com fake LLM + fake MCP.
* ğŸ§ª **CI local**: `cargo test --all`.
* ğŸ’¾ **Commit**: `test: unit and offline e2e for react flow`

---

## Fase 13 â€” Robustez de rede e retries

* [ ] **OpenAI**: retry com backoff para `429`/`5xx`; respeito a `Retry-After`.
* [ ] **Timeouts** configurÃ¡veis.
* [ ] **MCP**: fallback se o child morrer (restart limitado).
* ğŸ§ª **Teste manual**: simular falhas (desligar rede/derrubar server) e observar comportamento.
* ğŸ’¾ **Commit**: `feat(llm/mcp): retries, timeouts and graceful failures`

---

## Fase 14 â€” Tools mais Ãºteis

* [ ] **`http_get(url)`** (com whitelist simples).
* [ ] **`fs_read(path)`** (sandbox/whitelist).
* [ ] **`python_eval`** (se quiser; isolado, com limite).
* ğŸ§ª **Teste manual**: perguntar algo que exige web/file; observar toolcall/result.
* ğŸ’¾ **Commit**: `feat(mcp-server): http_get and fs_read tools`

---

## Fase 15 â€” Observabilidade & mÃ©tricas

* [ ] **TraÃ§os**: spans por request/grafo/nÃ³.
* [ ] **MÃ©tricas simples**: contadores de toolcalls, latÃªncia de LLM, tokens (se disponÃ­vel), erros.
* [ ] **Export**: log estruturado JSON opcional.
* ğŸ§ª **Teste manual**: ativar modo mÃ©tricas; ver nÃºmeros apÃ³s conversa.
* ğŸ’¾ **Commit**: `feat(obs): tracing spans and basic counters`

---

## Fase 16 â€” Empacotamento

* [ ] **Bin Ãºnico** para CLI; `mcp-server` como segundo bin.
* [ ] **Make/Justfile** para comandos padrÃ£o (build, test, run).
* [ ] **Dockerfiles** (opcional).
* ğŸ§ª **Teste manual**: rodar em mÃ¡quina â€œlimpaâ€ com apenas `OPENAI_API_KEY`.
* ğŸ’¾ **Commit**: `chore: release packaging and run scripts`

---

## Fase 17 â€” Extras (opcionais)

* [ ] **Prompt templates**/profiles (instruÃ§Ãµes por tarefa).
* [ ] **Corte de contexto** (janela deslizante).
* [ ] **Plugins de provider**: Azure, Anthropic (adapter).
* [ ] **Front-end**: expor WS/HTTP e streamar eventos (para UI).
* ğŸ’¾ **Commit**: `feat: provider plugins / http bridge`

---

### CritÃ©rios de â€œpronto para demoâ€

* [ ] Perguntas via CLI com **streaming** fluido.
* [ ] Toolcall â†’ MCP tool â†’ ToolResult â†’ resposta final incorporando resultado.
* [ ] Config por flags/env, logs Ãºteis, session persistindo.
* [ ] Testes unitÃ¡rios bÃ¡sicos passando.

---

Quando disser â€œokâ€, comeÃ§amos na **Fase 0** e sigo te entregando **o menor corte de cÃ³digo testÃ¡vel** por etapa, com comandos e exemplos de uso.
